{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZEC10hrOshG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as dataloader\n",
        "from torch.nn import attention\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformation_opertaion = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "W8HxFyoJPgJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transformation_opertaion)\n",
        "val_dataset = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transformation_opertaion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qb6dvvPCU3",
        "outputId": "3fa037af-3166-4dcd-995f-50cf27e4451b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 572kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.53MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.34MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = dataloader.DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "val_loader = dataloader.DataLoader(val_dataset, batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "id": "qYFg1W8mP4_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "batch_size = 64\n",
        "num_channels = 1\n",
        "patch_size = 7\n",
        "img_size = 28\n",
        "num_patches = (img_size // patch_size) ** 2\n",
        "embedding_dim = 64\n",
        "attention_heads = 4\n",
        "transformer_blocks = 4\n",
        "mlp_hidden_nodes = 128\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "l7lnbQTfQonw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch Embedding\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self, num_channels, patch_size, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.patch_embed = nn.Conv2d(num_channels, embedding_dim, kernel_size = patch_size, stride = patch_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.patch_embed(x)\n",
        "    x = x.flatten(2).transpose(1, 2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dapSJJXcR3y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Transformer Encoder\n",
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, attention_heads, mlp_hidden_nodes):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
        "    self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
        "    self.multihead_attention = nn.MultiheadAttention(embedding_dim, attention_heads,batch_first = True)\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(embedding_dim, mlp_hidden_nodes),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(mlp_hidden_nodes, embedding_dim)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = x\n",
        "    x = self.layer_norm1(x)\n",
        "    x = self.multihead_attention(x, x, x)[0]\n",
        "    x = residual + x\n",
        "    residual = x\n",
        "    x = self.layer_norm2(x)\n",
        "    x = self.mlp(x)\n",
        "    x  = residual + x\n",
        "    return x"
      ],
      "metadata": {
        "id": "lQq-xkmaHdb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Head\n",
        "class MLPHead(nn.Module):\n",
        "  def __init__(self, embedding_dim, num_classes):\n",
        "    super(MLPHead, self).__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
        "    self.mlp_head = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer_norm1(x)\n",
        "    # The classification token is already selected in VisionTransformer forward method.\n",
        "    # Removing the following line as it's redundant and causes incorrect shape.\n",
        "    # x = x[:, 0]\n",
        "    x = self.mlp_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VJczG94dLpQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VisionTrnasformers\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VisionTransformer, self).__init__()\n",
        "    self.patch_embedding = PatchEmbedding(num_channels, patch_size, embedding_dim)\n",
        "    self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
        "    self.position_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embedding_dim))\n",
        "    self.transformer_blocks = nn.Sequential(*[TransformerEncoder(embedding_dim, attention_heads, mlp_hidden_nodes) for _ in range(transformer_blocks)])\n",
        "    self.mlp_head = MLPHead(embedding_dim, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = x.size(0)\n",
        "    x = self.patch_embedding(x)\n",
        "    cls_token = self.cls_token.expand(B, -1, -1)\n",
        "    x = torch.cat((cls_token, x), dim = 1)\n",
        "    x = x + self.position_embedding\n",
        "    x = self.transformer_blocks(x)\n",
        "    x = x[:, 0]\n",
        "    x = self.mlp_head(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "QIToRGEwMOtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VisionTransformer().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TSlRwp3yOVUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  train_correct = 0\n",
        "  print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Fix for accuracy calculation\n",
        "    train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"Epoch %{epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss / len(train_loader)}\")\n",
        "    print(f\"Train Accuracy: {train_correct / len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQfinOpOqwl",
        "outputId": "1b2a67a3-922b-46f5-96dc-899e568ee040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Epoch %1/10\n",
            "Train Loss: 0.0751417811934167\n",
            "Train Accuracy: 62.424307036247335\n",
            "Epoch 2/10\n",
            "Epoch %2/10\n",
            "Train Loss: 0.06157587955260018\n",
            "Train Accuracy: 62.68017057569296\n",
            "Epoch 3/10\n",
            "Epoch %3/10\n",
            "Train Loss: 0.05446083324195356\n",
            "Train Accuracy: 62.850746268656714\n",
            "Epoch 4/10\n",
            "Epoch %4/10\n",
            "Train Loss: 0.04575147776259308\n",
            "Train Accuracy: 63.00319829424307\n",
            "Epoch 5/10\n",
            "Epoch %5/10\n",
            "Train Loss: 0.043470071275472276\n",
            "Train Accuracy: 63.09808102345416\n",
            "Epoch 6/10\n",
            "Epoch %6/10\n",
            "Train Loss: 0.0397842470206507\n",
            "Train Accuracy: 63.137526652452024\n",
            "Epoch 7/10\n",
            "Epoch %7/10\n",
            "Train Loss: 0.03604383460061847\n",
            "Train Accuracy: 63.16098081023454\n",
            "Epoch 8/10\n",
            "Epoch %8/10\n",
            "Train Loss: 0.030236760621951488\n",
            "Train Accuracy: 63.34434968017057\n",
            "Epoch 9/10\n",
            "Epoch %9/10\n",
            "Train Loss: 0.03164076991826058\n",
            "Train Accuracy: 63.31556503198294\n",
            "Epoch 10/10\n",
            "Epoch %10/10\n",
            "Train Loss: 0.026201935721931656\n",
            "Train Accuracy: 63.4136460554371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cff7bd81",
        "outputId": "b44576ac-5c3a-4f70-ee22-05eeabbc9628"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  train_correct = 0\n",
        "  print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Fix for accuracy calculation\n",
        "    train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  # Validation loop\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  val_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  # Print training and validation results\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "    print(f\"Train Accuracy: {train_correct / len(train_loader.dataset):.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_correct / len(val_loader.dataset):.4f}\")\n",
        "\n",
        "  model.train() # Set model back to training mode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 0.0183\n",
            "Train Accuracy: 0.9939\n",
            "Validation Loss: 0.0926\n",
            "Validation Accuracy: 0.9773\n",
            "Epoch 2/10\n",
            "Train Loss: 0.0193\n",
            "Train Accuracy: 0.9933\n",
            "Validation Loss: 0.0688\n",
            "Validation Accuracy: 0.9810\n",
            "Epoch 3/10\n",
            "Train Loss: 0.0162\n",
            "Train Accuracy: 0.9946\n",
            "Validation Loss: 0.0657\n",
            "Validation Accuracy: 0.9828\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0189\n",
            "Train Accuracy: 0.9938\n",
            "Validation Loss: 0.0676\n",
            "Validation Accuracy: 0.9813\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0139\n",
            "Train Accuracy: 0.9952\n",
            "Validation Loss: 0.0749\n",
            "Validation Accuracy: 0.9815\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0160\n",
            "Train Accuracy: 0.9945\n",
            "Validation Loss: 0.0741\n",
            "Validation Accuracy: 0.9803\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0174\n",
            "Train Accuracy: 0.9940\n",
            "Validation Loss: 0.0797\n",
            "Validation Accuracy: 0.9784\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0127\n",
            "Train Accuracy: 0.9957\n",
            "Validation Loss: 0.0644\n",
            "Validation Accuracy: 0.9833\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0138\n",
            "Train Accuracy: 0.9953\n",
            "Validation Loss: 0.0828\n",
            "Validation Accuracy: 0.9791\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0121\n",
            "Train Accuracy: 0.9959\n",
            "Validation Loss: 0.0741\n",
            "Validation Accuracy: 0.9809\n"
          ]
        }
      ]
    }
  ]
}